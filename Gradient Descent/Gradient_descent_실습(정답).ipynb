{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc6f9bab",
   "metadata": {},
   "source": [
    "# Model1\n",
    "Model : $y = ax + b$이라 하자. \\\n",
    "Loss : $(y - \\hat{y})^2$ where $\\hat{y} = ax + b$ \\\n",
    "Loss L과 input data $(x,y)$ 대하여 에 대하여 ${\\operatorname{d}\\!L\\over\\operatorname{d}\\!a}$ ${\\operatorname{d}\\!L\\over\\operatorname{d}\\!b}$를 구하여 다음과 같이 weight : $a,b$를 업데이트 한다.\\\n",
    "$a = a - lr * {\\operatorname{d}\\!L\\over\\operatorname{d}\\!a}$ \\\n",
    "$b = b - lr * {\\operatorname{d}\\!L\\over\\operatorname{d}\\!b}$ \\\n",
    "이때 lr은 learning rate로 기본값을 0.01로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7804d80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, a, b):\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "\n",
    "    def __call__(self, x):\n",
    "        a = self.a\n",
    "        b = self.b\n",
    "        return self.y_hat(a, b, x)\n",
    "\n",
    "    def y_hat(self, a, b, x):\n",
    "        return a * x + b\n",
    "\n",
    "    def loss(self, a, b, x, y):\n",
    "        return (y - self.y_hat(a, b, x)) ** 2\n",
    "\n",
    "    def gradient(self, x, y, h=1e-8):\n",
    "        a, b = self.a, self.b\n",
    "        gradient_a = (self.loss(a + h, b, x, y) - self.loss(a, b, x, y)) / h\n",
    "        gradient_b = (self.loss(a, b + h, x, y) - self.loss(a, b, x, y)) / h\n",
    "        return gradient_a, gradient_b\n",
    "\n",
    "    def weight_update(self, x, y, lr=0.01):\n",
    "        grad_a, grad_b = self.gradient(x, y)\n",
    "        self.a = self.a - lr * grad_a\n",
    "        self.b = self.b - lr * grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f14dc2",
   "metadata": {},
   "source": [
    "## 데이터 하나에 대하여 구해보기!\n",
    "input data가 $(x,y) = (3,1)$로 주어질때 한번의 업데이트 이후 a와 b 값을 확인하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ed305ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before : a = 2.00, b = 1.00\n",
      "After  : a = 1.64, b = 0.88\n"
     ]
    }
   ],
   "source": [
    "model = Model(2, 1)\n",
    "x, y = 3, 1\n",
    "print(f\"Before : a = {model.a:.2f}, b = {model.b:.2f}\")\n",
    "for epoch in range(1):\n",
    "    model.weight_update(x, y)\n",
    "print(f\"After  : a = {model.a:.2f}, b = {model.b:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f666396",
   "metadata": {},
   "source": [
    "## 10000번의 학습 이후 y_hat확인\n",
    "input data가 $(x,y) = (3,1)$로 주어질때 10000번의 weight 업데이트를 진행하고 y와 y_hat이 같은지 확인해 보세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6265f1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before : a = 2.00, b = 1.00\n",
      "After  : a = 0.20, b = 0.40\n",
      "y = 1.00, y_hat = 1.00\n"
     ]
    }
   ],
   "source": [
    "model = Model(2, 1)\n",
    "x, y = 3, 1\n",
    "print(f\"Before : a = {model.a:.2f}, b = {model.b:.2f}\")\n",
    "for epoch in range(10000):\n",
    "    model.weight_update(x, y)\n",
    "print(f\"After  : a = {model.a:.2f}, b = {model.b:.2f}\")\n",
    "print(f\"y = {y:.2f}, y_hat = {model(x):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc713d5",
   "metadata": {},
   "source": [
    "# Model2\n",
    "Model Class를 상속받아 데이터가 2개 이상으로 들어오는 경우 Gradient의 평균을 계산하여 업데이트하는 모델을 만드세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df215618",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchModel(Model):\n",
    "    def __init__(self, a, b):\n",
    "        super().__init__(a, b)\n",
    "\n",
    "    def batch_gradient(self, X, Y, h=1e-8):\n",
    "        batch_gradient_a, batch_gradient_b = [], []\n",
    "        for x, y in zip(X, Y):\n",
    "            gradient_a, gradient_b = self.gradient(x, y)\n",
    "            batch_gradient_a.append(gradient_a)\n",
    "            batch_gradient_b.append(gradient_b)\n",
    "        batch_gradient_a = sum(batch_gradient_a) / len(batch_gradient_a)\n",
    "        batch_gradient_b = sum(batch_gradient_b) / len(batch_gradient_b)\n",
    "        return batch_gradient_a, batch_gradient_b\n",
    "\n",
    "    def weight_update(self, X, Y, lr=0.01):\n",
    "        grad_a, grad_b = self.batch_gradient(X, Y)\n",
    "        self.a = self.a - lr * grad_a\n",
    "        self.b = self.b - lr * grad_b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7eb957a",
   "metadata": {},
   "source": [
    "## 데이터 하나에 대하여 구해보기!\n",
    "input data가 $(𝑥,𝑦)=\\{(3,1),(-1,5)\\}$로 주어질때 한번의 업데이트 이후 a와 b 값을 확인하세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d47f9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before : a = 2.00, b = 1.00\n",
      "After  : a = 1.76, b = 1.00\n"
     ]
    }
   ],
   "source": [
    "batch_model = BatchModel(2, 1)\n",
    "X = [3, -1]\n",
    "Y = [1, 5]\n",
    "print(f\"Before : a = {batch_model.a:.2f}, b = {batch_model.b:.2f}\")\n",
    "for epoch in range(1):\n",
    "    batch_model.weight_update(X, Y)\n",
    "print(f\"After  : a = {batch_model.a:.2f}, b = {batch_model.b:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb7f42a",
   "metadata": {},
   "source": [
    "## 10000번의 학습 이후 y_hat확인\n",
    "input data가 (𝑥,𝑦)={(3,1),(−1,5)}로 주어질때 한번의 업데이트 이후 a와 b 값을 확인하세요! \\\n",
    "우리의 모델은 선형모델로 일차직선을 의미하는데 두 점이 주어져 유일하게 한 직선을 결정할 수 있어요 \\\n",
    "weight a와 b가 두 점을 지나는 유일한 직선을 표현할 수 있는지 확인해 보세요!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff997866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before : a = 2.00, b = 1.00\n",
      "After  : a = -1.00, b = 4.00\n",
      "y = 1.00, y_hat = 1.00\n"
     ]
    }
   ],
   "source": [
    "batch_model = BatchModel(2, 1)\n",
    "X = [3, -1]\n",
    "Y = [1, 5]\n",
    "print(f\"Before : a = {batch_model.a:.2f}, b = {batch_model.b:.2f}\")\n",
    "for epoch in range(10000):\n",
    "    batch_model.weight_update(X, Y)\n",
    "print(f\"After  : a = {batch_model.a:.2f}, b = {batch_model.b:.2f}\")\n",
    "print(f\"y = {y:.2f}, y_hat = {batch_model(x):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

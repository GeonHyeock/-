# 해당자료의 목적 및 대상
### [목적]
- 다양한 시행착오와 문제를 겪고 회고하며 문제해결 능력을 기르기 위해 좀 더 본질적인 기본기의 중요성을 깨달았습니다.

    기존에 좀 더 깊이 탐구했으면 좋았을 내용에 대하여 공유하고자 해당 자료를 정리하게 되었습니다.

----

### [대상]
- 교내 연구실의 신입 학부연구생 교육조교로 활동하며 해당 학습자료로 일부 사용했습니다.
- "부스트클래스 : AI 엔지니어 기초 다지기"의 교육코치로 활동하며 담당 훈련생들 대상으로 교육과정 외 보충학습자료로 일부 사용하였습니다.
- AI에 관심있는 누구나 해당 자료를 사용하셔도 좋습니다.
---



<details>
<summary>학습 자료</summary>

## Gradient Descent : Linear Model 학습과정 이해하기

- 목표 : Gradient Descent를 이해하고 Linear Model을 통해 Weight를 Update하는 방법을 이해하기 
- [Link](Gradient_Descent)

## Backpropagation : FC Layer의 학습과정 이해하기

- 목표 : Chain Rule을 바탕으로 Forward와 Backward과정을 통하여 Weight를 Update하는 방법을 이해하기
- [Link](Backpropagation)

## CLT and MLE : 중심극한정리와 최대가능도 추정량의 불변성과 정규근사

- 목표 : 중심극한정리와 최대가능도 추정량의 성질 중 불변성과 정규근사를 이해하기
- 추가학습 : 균등분포를 활용하여 특정 확률분포로부터 랜덤샘플을 얻는방법 이해하기
- [Link](CLT&MLE)



</details>




<details>
<summary>TODO List</summary>

- Gradient Descent 손필기 설명 보충
- Backpropagation 손필기 설명 보충
- Weight Init
- MCMC
- Loss와 Metric의 이해
- 부동소수점의 오차

</details>



